{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying handwritten digits\n",
    "\n",
    "**What are the steps to build a network in PyTorch?**\n",
    "\n",
    "* Data pipeline - DataLoader, Transforms, Working with images\n",
    "* \"Babysitting the learning process\" - Batch size, validation set, 1st-layer visualizations\n",
    "* First approach to work with images - Fully-connected network for [MNIST data set][mnist]\n",
    "\n",
    "\"Build a neural network in your browser\" - [deeplearnjs.org/demos/model-builder][model-builder]\n",
    "\n",
    "<a href=\"https://deeplearnjs.org/demos/model-builder/\">\n",
    "    <img src=\"images/tfjs-mnist.png\" width=\"400px\" />\n",
    "</a>\n",
    "\n",
    "[mnist]:http://yann.lecun.com/exdb/mnist/index.html\n",
    "[model-builder]:https://deeplearnjs.org/demos/model-builder/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import torch\n",
    "print(\"Torch version:\", torch.__version__)\n",
    "\n",
    "import torchvision\n",
    "print(\"Torchvision version:\", torchvision.__version__)\n",
    "\n",
    "import numpy as np\n",
    "print(\"Numpy version:\", np.__version__)\n",
    "\n",
    "import matplotlib\n",
    "print(\"Matplotlib version:\", matplotlib.__version__)\n",
    "\n",
    "import PIL\n",
    "print(\"PIL version:\", PIL.__version__)\n",
    "\n",
    "import IPython\n",
    "print(\"IPython version:\", IPython.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Matplotlib\n",
    "%matplotlib inline\n",
    "#%config InlineBackend.figure_format = 'retina' # If you have a retina screen\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading and preprocessing\n",
    "\n",
    "Why data loaders - Source: [Data Loading and Processing Tutorial][dataloader-tutorial] by Sasank Chilamkurthy\n",
    "\n",
    "> A lot of effort in solving any machine learning problem goes in to preparing the data. PyTorch provides many tools to make data loading easy and hopefully, to make your code more readable.\n",
    "\n",
    "Why is it important?\n",
    "\n",
    "* **Data augmentation** - improve training and generalization\n",
    "* **Handle large data sets** - memory issues / speed ex. prefetching\n",
    "\n",
    "[dataloader-tutorial]:https://pytorch.org/tutorials/beginner/data_loading_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Data set\n",
    "preprocessing = transforms.Compose([\n",
    "    transforms.ToTensor(), # To PyTorch tensors\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "train_set = torchvision.datasets.MNIST(root='data', train=True, download=True, transform=preprocessing)\n",
    "valid_set = torchvision.datasets.MNIST(root='data', train=False, download=True, transform=preprocessing)\n",
    "\n",
    "# Data loader for the \"train\" set\n",
    "# - Set number of workers with num_workers\n",
    "train_loader = DataLoader(train_set, batch_size=64, shuffle=True)\n",
    "\n",
    "# Data loader for the \"validation\" step\n",
    "valid_sampler = torch.utils.data.sampler.SubsetRandomSampler(\n",
    "    # Validation set is too large, take a subset for efficiency\n",
    "    np.random.choice(np.arange(len(valid_set)), size=200, replace=False)\n",
    ")\n",
    "valid_loader = DataLoader(valid_set, batch_size=64, shuffle=False, sampler=valid_sampler)\n",
    "\n",
    "# Get first batch of data from the \"train\" set\n",
    "train_iter = iter(train_loader)\n",
    "images, labels = next(train_iter)\n",
    "\n",
    "print('Shape of image Tensor:', images.shape)\n",
    "print('Labels:', labels)\n",
    "\n",
    "# Plot it\n",
    "grid = torchvision.utils.make_grid(images, normalize=True)\n",
    "plt.imshow(grid.numpy().transpose((1, 2, 0)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"Babysitting the learning process\"\n",
    "\n",
    "How to monitor the learning process?\n",
    "\n",
    "* **Monitor loss value** - Oscillations, how it decreases\n",
    "* **Validation set** - Overfitting, model complexity\n",
    "\n",
    "**First-layer visualizations** - Source [CS231n course][cs231-baby]\n",
    "\n",
    "<img src=\"images/cs231n-layer1vis.png\" width=\"600px\" />\n",
    "\n",
    "[cs231-baby]:http://cs231n.github.io/neural-networks-3/#baby\n",
    "\n",
    "PyTorch implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arbitrary 2-layers model\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(in_features=28*28, out_features=64),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(in_features=64, out_features=10)\n",
    ")\n",
    "\n",
    "# Get the weights matrix\n",
    "weights = model[0].weight.data\n",
    "\n",
    "# Visualize hidden units\n",
    "def plot_layer1(weights, axis):\n",
    "    # Shape of weights matrix\n",
    "    n_out, n_in = weights.shape\n",
    "    assert n_in == 784 # Should be the first layer\n",
    "\n",
    "    # Create a grid\n",
    "    n_cells = min(16, n_out)\n",
    "    grid = torchvision.utils.make_grid(\n",
    "        weights[:n_cells].view(n_cells, 1, 28, 28),\n",
    "        nrow=4, normalize=True\n",
    "    )\n",
    "    \n",
    "    # Plot it\n",
    "    axis.imshow(grid.numpy().transpose((1, 2, 0)), aspect='auto')\n",
    "    \n",
    "fig = plt.figure(figsize=(3, 3))\n",
    "plot_layer1(weights, fig.gca())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the digit classifier\n",
    "\n",
    "**Training with small batches of data**\n",
    "\n",
    "```python\n",
    "# Create the model\n",
    "...\n",
    "\n",
    "t = 0 # Number of samples seen\n",
    "print_step = 200 # Refresh rate\n",
    "\n",
    "for epoch in range(1, 10**5):\n",
    "    # Train by small batches of data\n",
    "    for batch, (batch_X, batch_y) in enumerate(train_loader, 1):\n",
    "        # Forward pass\n",
    "        ...\n",
    "\n",
    "        # Backpropagation\n",
    "        ...\n",
    "\n",
    "        if t%print_step == 0:\n",
    "            # Visualize what the network learned\n",
    "            ...\n",
    "            \n",
    "        # Update t\n",
    "        t += train_loader.batch_size\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# Create model\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(in_features=28*28, out_features=10),\n",
    ")\n",
    "\n",
    "# Criterion and optimizer for \"training\"\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, weight_decay=1)\n",
    "\n",
    "# Forward step\n",
    "def forward(X):\n",
    "    X_tensor = torch.FloatTensor(X)\n",
    "    X_reshaped = X_tensor.view(-1, 28*28) # Reshape the input!\n",
    "    X_variable = torch.autograd.Variable(X_reshaped)\n",
    "    return model(X_variable)\n",
    "\n",
    "# Backprop step\n",
    "def compute_loss(output, target):\n",
    "    y_tensor = torch.LongTensor(target)\n",
    "    y_variable = torch.autograd.Variable(y_tensor)\n",
    "    return criterion(output, y_variable)\n",
    "\n",
    "def backpropagation(output, target):\n",
    "    optimizer.zero_grad() # Clear the gradients\n",
    "    loss = compute_loss(output, target) # Compute loss\n",
    "    loss.backward() # Backpropagation\n",
    "    optimizer.step() # Let the optimizer adjust our model\n",
    "    return loss.data\n",
    "\n",
    "# Helper function\n",
    "def get_accuracy(output, y):\n",
    "    predictions = torch.argmax(output, dim=1) # Max activation\n",
    "    is_correct = np.equal(predictions, y)\n",
    "    return is_correct.numpy().mean()\n",
    "    \n",
    "# Create a figure to visualize the results\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(nrows=1, ncols=3, figsize=(12, 3))\n",
    "    \n",
    "try:\n",
    "    # Collect loss / accuracy values\n",
    "    stats = defaultdict(list)\n",
    "    t = 0 # Number of samples seen\n",
    "    print_step = 200 # Refresh rate\n",
    "    \n",
    "    for epoch in range(1, 10**5):\n",
    "        # Train by small batches of data\n",
    "        for batch, (batch_X, batch_y) in enumerate(train_loader, 1):\n",
    "            # Forward pass & backpropagation\n",
    "            output = forward(batch_X)\n",
    "            loss = backpropagation(output, batch_y)\n",
    "            \n",
    "            # Log \"train\" stats\n",
    "            stats['train_loss'].append(loss)\n",
    "            stats['train_acc'].append(get_accuracy(output, batch_y))\n",
    "            stats['train_t'].append(t)\n",
    "\n",
    "            if t%print_step == 0:\n",
    "                # Log \"validation\" stats\n",
    "                loss_vals, acc_vals = [], []\n",
    "                for X, y in valid_loader:\n",
    "                    output = forward(X)\n",
    "                    loss_vals.append(compute_loss(output, y).data)\n",
    "                    acc_vals.append(get_accuracy(output, y))\n",
    "                    \n",
    "                stats['val_loss'].append(np.mean(loss_vals))\n",
    "                stats['val_acc'].append(np.mean(acc_vals))\n",
    "                stats['val_t'].append(t)\n",
    "                \n",
    "                # Plot what the network learned\n",
    "                ax1.cla()\n",
    "                ax1.set_title('Epoch {}, batch {:,}'.format(epoch, batch))\n",
    "                plot_layer1(model[0].weight.data, ax1)\n",
    "                ax2.cla()\n",
    "                ax2.set_title('Loss, val: {:.3f}'.format(np.mean(stats['val_loss'][-10:])))\n",
    "                ax2.plot(stats['train_t'], stats['train_loss'], label='train')\n",
    "                ax2.plot(stats['val_t'], stats['val_loss'], label='valid')\n",
    "                ax2.legend()\n",
    "                ax3.cla()\n",
    "                ax3.set_title('Accuracy, val: {:.3f}'.format(np.mean(stats['val_acc'][-10:])))\n",
    "                ax3.plot(stats['train_t'], stats['train_acc'], label='train')\n",
    "                ax3.plot(stats['val_t'], stats['val_acc'], label='valid')\n",
    "                ax3.set_ylim(0, 1)\n",
    "                ax3.legend()\n",
    "\n",
    "                # Jupyter trick\n",
    "                IPython.display.clear_output(wait=True)\n",
    "                IPython.display.display(fig)\n",
    "                \n",
    "            # Update t\n",
    "            t += train_loader.batch_size\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    # Clear output\n",
    "    IPython.display.clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tasks**\n",
    "\n",
    "* Hidden layers - Add a hidden layer with 64 units and ReLU activation\n",
    "* Sanity check - Achieve a loss of 0 on a small random subset of the data\n",
    "* Learning rate - Test different values, what are the effects on the loss\n",
    "* Model complexity - Play with the number of layers and units, observe overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Small challenge - Plot output activations for a few images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional resources\n",
    "\n",
    "Nice visualizations\n",
    "\n",
    "* Visualize MNIST data set with unsupervised learning - [projector.tensorflow.org][tf-projector]\n",
    "\n",
    "To go deeper\n",
    "\n",
    "* Weight Initialization - [cs231n course][cs231-init]\n",
    "\n",
    "[tf-projector]:https://projector.tensorflow.org/\n",
    "[cs231-init]:http://cs231n.github.io/neural-networks-2/#init"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
